example_num: 50
example_seperator: ' : '
gpu_memory_utilization: 0.8
implimentation: vllm
lke_index: 0
lke_type: zp-lke
max_model_len: 2048
max_new_tokens: 50
model_name: llama2-7b
model_path: /NS/llm-1/nobackup/qwu/llm_base_model/meta-llama/Meta-Llama-3-8B
num_options: 100
prompt_logprobs: 1
random_seed: 10
save_path: /NS/llm-1/work/qwu/lke_open_code/result
tempature: 0.0
tensor_parallel_size: 1
test_dataset_name: /NS/llm-1/nobackup/qwu/dataset/T-Rex-MC
test_index_begin: 0
test_index_end: 10
test_relation_id: 1
tokenizer_path: /NS/llm-1/nobackup/qwu/llm_base_model/meta-llama/Meta-Llama-3-8B
trust_remote_code: true
